{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLhgpxZJREIW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Jupyter setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# web scraping\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8,hu;q=0.7\",\n",
    "    \"Referer\": \"https://google.com\",\n",
    "    \"DNT\": \"1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Libraries for visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Selenium setup for dynamic web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "#Selenium setup\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(f'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
    "\n",
    "watchlist_driver = webdriver.Chrome(options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Libraries / programs for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import sys\n",
    "print(sys.executable)\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTK4YjZRSskP",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Web scraping movie cards and urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Finding movie cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND THE MOVIE CARDS ON EVERY PAGE ON MY WATCHLIST\n",
    "# runs for 98 seconds / 138 seconds\n",
    "watchlist_driver = webdriver.Chrome(options=options)\n",
    "page = 1\n",
    "all_movie_cards =[]\n",
    "\n",
    "\n",
    "while page <= 12 :  #change the number of the pages to 1 for testing purposes\n",
    "  try:\n",
    "    watchlist_url = f\"https://www.imdb.com/user/ur40669107/watchlist/?ref_=hm_nv_urwls_all&page={page}\"\n",
    "    watchlist_driver.get(watchlist_url)\n",
    "\n",
    "    watchlist_page_source = watchlist_driver.page_source\n",
    "    # Scroll down the page to load all watchlist items\n",
    "    last_height = watchlist_driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        watchlist_driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load the new content\n",
    "        time.sleep(1)\n",
    "\n",
    "        new_height = watchlist_driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    watchlist_page_source = watchlist_driver.page_source\n",
    "\n",
    "    soup = bs(watchlist_page_source, 'lxml')\n",
    "\n",
    "    imdb_cards = soup.find_all('li', class_='ipc-metadata-list-summary-item')\n",
    "\n",
    "    all_movie_cards.extend(imdb_cards)\n",
    "\n",
    "    page +=1\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error on page {page}: {e}\")\n",
    "    break\n",
    "\n",
    "print(f\"Total movie cards found: {len(all_movie_cards)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates from movie cards list\n",
    "\n",
    "unique_movie_cards = list(dict.fromkeys(all_movie_cards))\n",
    "print(f\"Total unique movie cards found: {len(unique_movie_cards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQtjKcCj9pld",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Titles and urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the movie titles and separate links for the movies\n",
    "imdb_movies = []\n",
    "only_url = []\n",
    "\n",
    "for movie in unique_movie_cards:\n",
    "  title_link = movie.find('a', class_=\"ipc-title-link-wrapper\")\n",
    "  title = None\n",
    "  if title_link:\n",
    "    href = title_link.get('href')\n",
    "\n",
    "    h3 = title_link.find('h3', class_=\"ipc-title__text ipc-title__text--reduced\")\n",
    "    title = h3.get_text(strip=True)\n",
    "\n",
    "    title = re.sub(r'^\\d+\\.\\s*', '', title)\n",
    "\n",
    "    if href:\n",
    "      full_url = \"https://www.imdb.com\" + href\n",
    "      imdb_movies.append({\n",
    "          'title': title,\n",
    "          'url': full_url})\n",
    "      only_url.append(full_url)\n",
    "\n",
    "watchlist_movies_df = pd.DataFrame(imdb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total unique movies found: {len(watchlist_movies_df)}\")\n",
    "print(f\"Total unique urls found: {len(only_url)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the watchlist_movies_df\n",
    "watchlist_movies_df.to_csv('watchlist_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNnUlAmz9vjy",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Information via the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs for 43 seconds for 100 titles\n",
    "# runs for 201 seconds / 3.5 minutes for 500 titles\n",
    "# runs for ??? for 1000 titles\n",
    "# runs for roughly 20 minutes for 2700 titles\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "def fetch_movie(url):\n",
    "    current_movie_data = []\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = bs(response.content, \"lxml\")\n",
    "\n",
    "        # TITLE\n",
    "        try:\n",
    "            title_element = soup.find('h1', attrs={'data-testid': 'hero__pageTitle'})\n",
    "            title = title_element.get_text(strip=True) if title_element else None\n",
    "        except:\n",
    "            title = None\n",
    "        current_movie_data.append(title)\n",
    "\n",
    "        # YEAR\n",
    "        try:\n",
    "            year_div = soup.find('ul', class_=\"ipc-inline-list ipc-inline-list--show-dividers sc-cb6a22b2-2 aFhKV baseAlt baseAlt\")\n",
    "            year_next_level = year_div.find('li', class_=\"ipc-inline-list__item\")\n",
    "            year = year_next_level.find('a').get_text(strip=True)\n",
    "        except:\n",
    "            year = None\n",
    "        current_movie_data.append(year)\n",
    "\n",
    "        # RATING\n",
    "        try:\n",
    "            rating_span = soup.find('span', class_=\"sc-4dc495c1-1 lbQcRY\")\n",
    "            rating = rating_span.get_text(strip=True) if rating_span else None\n",
    "        except:\n",
    "            rating = None\n",
    "        current_movie_data.append(rating)\n",
    "\n",
    "        # SHORT PLOT\n",
    "        try:\n",
    "            plot = soup.find_all(\"span\", class_=\"sc-bf30a0e-2 bRimta\")\n",
    "            plot_text = plot[0].get_text(strip=True) if plot else None\n",
    "        except:\n",
    "            plot_text = None\n",
    "        current_movie_data.append(plot_text)\n",
    "\n",
    "        # AI SUMMARY\n",
    "        try:\n",
    "            ai_summary = soup.find_all('div', class_='ipc-html-content-inner-div')\n",
    "            summary_text = ai_summary[0].get_text(strip=True) if ai_summary else None\n",
    "        except:\n",
    "            summary_text = None\n",
    "        current_movie_data.append(summary_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        current_movie_data = [None, None, None, None, None]\n",
    "\n",
    "    return current_movie_data\n",
    "\n",
    "\n",
    "# Run in parallel\n",
    "all_movies = []\n",
    "urls = only_url #[:500]  # adjust here (100, 2700, etc.)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:  # 20 parallel requests\n",
    "    futures = [executor.submit(fetch_movie, url) for url in urls]\n",
    "    for future in as_completed(futures):\n",
    "        all_movies.append(future.result())\n",
    "\n",
    "print(f\"Fetched {len(all_movies)} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe from the scraped data\n",
    "summary_df = pd.DataFrame(all_movies, columns=['title', 'year','rating', 'plot', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export summary_df\n",
    "summary_df.to_csv('summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlV_DiS-S8Sz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Basic observations and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import summary_df\n",
    "summary_df = pd.read_csv('summary.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuYHceyq88L4",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of movies without year: {len(summary_df['title'][summary_df['year'] == 0])}\")\n",
    "print(f\"Total number of movies with year null: {len(summary_df['year'][summary_df['year'].isnull()])}\")\n",
    "print(f\"Total number of movies without rating: {len(summary_df['title'][summary_df['rating'].isnull()])}\")\n",
    "print(f\"Total number of movies without plot: {len(summary_df['title'][summary_df['plot'].isnull()])}\")\n",
    "print(f\"Total number of movies without summary: {len(summary_df['title'][summary_df['summary'].isnull()])}\")\n",
    "print(f\"Total number of movies without title: {len(summary_df['title'][summary_df['title'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Remove rows with missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where the year is 0\n",
    "summary_df = summary_df[summary_df['year'] != 0]\n",
    "summary_df = summary_df[summary_df['year'].isnull() == False]\n",
    "summary_df = summary_df[summary_df['plot'].isnull() == False]\n",
    "summary_df = summary_df[summary_df['summary'].isnull() == False]\n",
    "print(len(summary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['title'] = summary_df['title'].astype(str)\n",
    "summary_df['year'] = summary_df['year'].astype(int)\n",
    "summary_df['rating'] = summary_df['rating'].astype(float)\n",
    "summary_df['summary'] = summary_df['summary'].astype(str)\n",
    "summary_df['plot'] = summary_df['plot'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Adding 'era' and 'rate_bin' columns for better overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating bins in the year column\n",
    "min_year = summary_df['year'].min()\n",
    "max_year = summary_df['year'].max()\n",
    "\n",
    "bins = list(range(min_year, max_year, 25)) + [max_year]\n",
    "\n",
    "labels = [f'{bins[i]}-{bins[i+1]}' for i in range(len(bins)-1)]\n",
    "\n",
    "summary_df['era'] = pd.cut(summary_df['year'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "summary_df.groupby('era').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating bins in the rating column\n",
    "bins = [0, 2.5, 5, 7.5, 10]\n",
    "\n",
    "labels = ['0-2.5', '2.5-5', '5-7.5', '7.5-10']\n",
    "\n",
    "summary_df['rate_bin'] = pd.cut(summary_df['rating'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "summary_df.groupby('rate_bin').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Basic df visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=summary_df, x='year', y='rating', hue= 'era')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=summary_df,\n",
    "            kind='line',\n",
    "            x='year',\n",
    "            y='plot_sentiment_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=summary_df,\n",
    "            kind='line',\n",
    "            x='era',\n",
    "            y='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=summary_df,\n",
    "            kind='line',\n",
    "            x='era',\n",
    "            y='plot_sentiment_score',\n",
    "           style='rate_bin',\n",
    "           hue='rate_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=summary_df,\n",
    "                kind='box',\n",
    "                x='era',\n",
    "                y='rating')\n",
    "g.fig.suptitle('Rating throughout the eras',\n",
    "              y=1.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=summary_df,\n",
    "            kind='point',\n",
    "            x='era',\n",
    "            y='rating',\n",
    "            hue='era')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v98YpZzIFcv0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBuJaesTED2a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sentiment analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum sequence length for the model\n",
    "max_len = sentiment_analyzer.model.config.max_position_embeddings\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY THE SENT ANALYZER TO THE PLOT AND SUMMARY COLUMNS\n",
    "#RUNNING FOR 10-15 minutes\n",
    "\n",
    "def get_sentiment_score_in_chunks(text, max_len, sentiment_analyzer):\n",
    "    \"\"\"Analyzes sentiment of text in chunks and returns the average score.\"\"\"\n",
    "    chunks = [text[i:i + max_len] for i in range(0, len(text), max_len)]\n",
    "    chunk_scores = []\n",
    "    for chunk in chunks:\n",
    "        result = sentiment_analyzer(chunk)\n",
    "        score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else -result[0]['score']\n",
    "        chunk_scores.append(score)\n",
    "\n",
    "    if not chunk_scores:\n",
    "        return None  # Handle empty text case\n",
    "\n",
    "    # Calculate the average score\n",
    "    avg_score = sum(chunk_scores) / len(chunk_scores)\n",
    "    return avg_score\n",
    "\n",
    "def map_score_to_category(score):\n",
    "    \"\"\"Maps a sentiment score to one of 5 categories.\"\"\"\n",
    "    if score is None:\n",
    "        return 'Unknown'\n",
    "    elif score < -0.6: # Adjust the range based on the score calculation in the function above\n",
    "        return 'Strongly Negative'\n",
    "    elif score < -0.2:\n",
    "        return 'Negative'\n",
    "    elif score < 0.2:\n",
    "        return 'Neutral'\n",
    "    elif score < 0.6:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Strongly Positive'\n",
    "\n",
    "\n",
    "# Create sentiment results separately\n",
    "plot_sentiment_score = summary_df['plot'].apply(\n",
    "    lambda x: get_sentiment_score_in_chunks(x, max_len, sentiment_analyzer)\n",
    ")\n",
    "\n",
    "plot_sentiment_category = plot_sentiment_score.apply(map_score_to_category)\n",
    "\n",
    "summary_sentiment_score = summary_df['summary'].apply(\n",
    "    lambda x: get_sentiment_score_in_chunks(x, max_len, sentiment_analyzer)\n",
    ")\n",
    "\n",
    "summary_sentiment_category = summary_sentiment_score.apply(map_score_to_category)\n",
    "\n",
    "# Build a new DataFrame without modifying summary_df\n",
    "summary_with_sentiment_df = pd.DataFrame({\n",
    "    \"title\": summary_df['title'],\n",
    "    \"year\": summary_df['year'],\n",
    "    \"era\": summary_df['era'],\n",
    "    \"rating\":summary_df['rating'],\n",
    "    \"rate_bin\": summary_df['rate_bin'],\n",
    "    \"plot\": summary_df['plot'],\n",
    "    \"summary\": summary_df['summary'],\n",
    "    \"plot_sentiment_score\": plot_sentiment_score,\n",
    "    \"plot_sentiment_category\": plot_sentiment_category,\n",
    "    \"sentiment_score\": summary_sentiment_score,\n",
    "    \"sentiment_category\": summary_sentiment_category\n",
    "})\n",
    "\n",
    "# Show results\n",
    "print(f\"\\nPlot sentiment distribution:\")\n",
    "print(summary_with_sentiment_df['plot_sentiment_category'].value_counts())\n",
    "print(f\"\\nSummary sentiment distribution:\")\n",
    "print(summary_with_sentiment_df['sentiment_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Export / import the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export summary_with_sentiment_df\n",
    "summary_with_sentiment_df.to_csv('summary_with_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "summary_with_sentiment_df = pd.read_csv('summary_with_sentiment.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nPlot sentiment distribution:\")\n",
    "print(summary_with_sentiment_df['plot_sentiment_category'].value_counts())\n",
    "print(f\"\\nSummary sentiment distribution:\")\n",
    "print(summary_with_sentiment_df['sentiment_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(pd.crosstab(summary_with_sentiment_df['era'], summary_with_sentiment_df['sentiment_category']),\n",
    "            annot=True, fmt=\"d\", cmap=\"RdYlGn\", cbar=True)\n",
    "\n",
    "plt.title(\"Sentiment Distribution by Era\")\n",
    "plt.ylabel(\"Era\")\n",
    "plt.xlabel(\"Sentiment Category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Area charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'Strongly Negative': '#B22222',  # dark red\n",
    "    'Negative': '#FFA500',           # orange\n",
    "    'Neutral': '#FFD700',            # yellow\n",
    "    'Positive': '#98FB98',           # light green\n",
    "    'Strongly Positive': '#006400'   # dark green\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by YEAR and PLOT SENTIMENT CATEGORY and count the occurrences\n",
    "sentiment_by_year = summary_with_sentiment_df.groupby(['year', 'plot_sentiment_category']).size().unstack(fill_value=0)\n",
    "\n",
    "sentiment_order = ['Strongly Negative', 'Negative', 'Positive', 'Strongly Positive'] # Removed 'Neutral'\n",
    "sentiment_by_year = sentiment_by_year[sentiment_order]\n",
    "\n",
    "\n",
    "# Create the stacked area chart\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sentiment_by_year.plot(kind='area', stacked=True, color=[colors[col] for col in sentiment_order], figsize=(15, 8))\n",
    "\n",
    "plt.title('Distribution of Plot Sentiment Categories Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Movies')\n",
    "\n",
    "ax.set_xticks(sentiment_by_year.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='Sentiment Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by YEAR and SENTIMENT CATEGORY and count the occurrences\n",
    "sentiment_by_year = summary_with_sentiment_df.groupby(['year', 'sentiment_category']).size().unstack(fill_value=0)\n",
    "\n",
    "sentiment_order = ['Negative', 'Neutral', 'Positive', 'Strongly Positive', 'Strongly Negative'] # Removed \n",
    "sentiment_by_year = sentiment_by_year[sentiment_order]\n",
    "\n",
    "# Create the stacked area chart\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sentiment_by_year.plot(kind='area', stacked=True, color=[colors[col] for col in sentiment_order], figsize=(15, 8))\n",
    "\n",
    "plt.title('Distribution of Sentiment Categories Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Movies')\n",
    "\n",
    "ax.set_xticks(sentiment_by_year.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='Sentiment Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by RATING and SENTIMENT CATEGORY and count the occurrences\n",
    "sentiment_by_rating = summary_with_sentiment_df.groupby(['rating', 'sentiment_category']).size().unstack(fill_value=0)\n",
    "\n",
    "sentiment_order = ['Negative', 'Neutral', 'Positive', 'Strongly Positive', 'Strongly Negative'] # Removed \n",
    "sentiment_by_rating = sentiment_by_rating[sentiment_order]\n",
    "\n",
    "# Create the stacked area chart\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sentiment_by_rating.plot(kind='area', stacked=True,color=[colors[col] for col in sentiment_order], figsize=(15, 8))\n",
    "\n",
    "plt.title('Distribution of Sentiment Categories Over the Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Movies')\n",
    "\n",
    "ax.set_xticks(sentiment_by_rating.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='Sentiment Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by RATING and PLOT SENTIMENT CATEGORY and count the occurrences\n",
    "sentiment_by_rating = summary_with_sentiment_df.groupby(['rating', 'plot_sentiment_category']).size().unstack(fill_value=0)\n",
    "\n",
    "sentiment_order = ['Negative', 'Positive', 'Strongly Positive', 'Strongly Negative'] # Removed 'Neutral'\n",
    "sentiment_by_rating = sentiment_by_rating[sentiment_order]\n",
    "\n",
    "# Create the stacked area chart\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sentiment_by_rating.plot(kind='area', stacked=True,color=[colors[col] for col in sentiment_order], figsize=(15, 8))\n",
    "\n",
    "plt.title('Distribution of PLot Sentiment Categories Over the ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Movies')\n",
    "\n",
    "ax.set_xticks(sentiment_by_rating.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='Sentiment Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt\n",
    "\n",
    "I'll show you a pandas df in csv format\n",
    "This df shows movies -- with title, year, plot, summary.\n",
    "Based on this df create 6 emotional categories that can fit the plot. \n",
    "Please return the exact same df in .csv format, separated by ; and add an extra column with the emotional categories.\n",
    "a line should look something like this: \"title;year;emotional_category\" \"The Godfather;1972;[actual emotional_category value]\"\n",
    "Return nothing else but the lines of the semicolon separated table in raw text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import summary_df\n",
    "summary_gpt_df = pd.read_csv('summary_with_emotions.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_gpt_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of movies without year: {len(summary_gpt_df['title'][summary_gpt_df['year'] == 0])}\")\n",
    "print(f\"Total number of movies with year null: {len(summary_gpt_df['title'][summary_gpt_df['year'].isnull()])}\")\n",
    "print(f\"Total number of movies without rating: {len(summary_gpt_df['title'][summary_gpt_df['rating'].isnull()])}\")\n",
    "print(f\"Total number of movies without plot: {len(summary_gpt_df['title'][summary_gpt_df['plot'].isnull()])}\")\n",
    "print(f\"Total number of movies without summary: {len(summary_gpt_df['title'][summary_gpt_df['summary'].isnull()])}\")\n",
    "print(f\"Total number of movies without title: {len(summary_gpt_df['title'][summary_gpt_df['title'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where the year is 0\n",
    "summary_gpt_df = summary_gpt_df[summary_gpt_df['year'] != 0]\n",
    "summary_gpt_df = summary_gpt_df[summary_gpt_df['year'].isnull() == False]\n",
    "summary_gpt_df = summary_gpt_df[summary_gpt_df['plot'].isnull() == False]\n",
    "summary_gpt_df = summary_gpt_df[summary_gpt_df['summary'].isnull() == False]\n",
    "print(len(summary_gpt_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_gpt_df['title'] = summary_gpt_df['title'].astype(str)\n",
    "summary_gpt_df['year'] = summary_gpt_df['year'].astype(int)\n",
    "summary_gpt_df['rating'] = summary_gpt_df['rating'].astype(float)\n",
    "summary_gpt_df['summary'] = summary_gpt_df['summary'].astype(str)\n",
    "summary_gpt_df['plot'] = summary_gpt_df['plot'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories\n",
    "\n",
    "#Cluster 1 â†’ Mostly negative / tragic tones (loss, death, hardship).\n",
    "#Cluster 2 â†’ Mixed, leaning neutral (descriptive, factual).\n",
    "#Cluster 3 â†’ Positive ðŸŽ‰ (hope, inspiration, love, uplifting endings).\n",
    "#Cluster 4 â†’ Mixed but slightly negative (conflict, struggle).\n",
    "#Cluster 5 â†’ Positive ðŸŽ‰ (friendship, adventure, optimism).\n",
    "#Cluster 6 â†’ Strongly negative (violence, crime, despair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping dictionary for the old and new names\n",
    "rename_mapping = {\n",
    "    'Category_1': 'Negative',\n",
    "    'Category_2': 'Neutral',\n",
    "    'Category_3': 'Positive',\n",
    "    'Category_4': 'Negative',\n",
    "    'Category_5': 'Positive',\n",
    "    'Category_6': 'Strongly Negative',\n",
    "}\n",
    "\n",
    "# Rename the categories in the 'Category' column\n",
    "summary_gpt_df['emotional_category'] = summary_gpt_df['emotional_category'].replace(rename_mapping)\n",
    "\n",
    "#Cluster 1 â†’ Mostly negative / tragic tones (loss, death, hardship).\n",
    "#Cluster 2 â†’ Mixed, leaning neutral (descriptive, factual).\n",
    "#Cluster 3 â†’ Positive ðŸŽ‰ (hope, inspiration, love, uplifting endings).\n",
    "#Cluster 4 â†’ Mixed but slightly negative (conflict, struggle).\n",
    "#Cluster 5 â†’ Positive ðŸŽ‰ (friendship, adventure, optimism).\n",
    "#Cluster 6 â†’ Strongly negative (violence, crime, despair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "print(f\"\\nSummary sentiment distribution:\")\n",
    "print(summary_gpt_df['emotional_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by RATING and SENTIMENT CATEGORY and count the occurrences\n",
    "sentiment_by_rating = summary_gpt_df.groupby(['rating', 'emotional_category']).size().unstack(fill_value=0)\n",
    "\n",
    "sentiment_order = ['Strongly Negative', 'Negative', 'Neutral', 'Positive']\n",
    "sentiment_by_rating = sentiment_by_rating[sentiment_order]\n",
    "\n",
    "# Create the stacked area chart\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sentiment_by_rating.plot(kind='area', stacked=True,color=[colors[col] for col in sentiment_order], figsize=(15, 8))\n",
    "\n",
    "plt.title('Distribution of Sentiment Categories based on the Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Movies')\n",
    "\n",
    "ax.set_xticks(sentiment_by_rating.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='Sentiment Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by YEAR and SENTIMENT CATEGORY and count the occurrences\n",
    "sentiment_by_year = summary_gpt_df.groupby(['year', 'emotional_category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Sort the columns to ensure consistent stacking order (optional but good practice)\n",
    "# You can adjust the order of categories in this list if you prefer a different order\n",
    "sentiment_order = ['Strongly Negative', 'Negative', 'Neutral', 'Positive']\n",
    "sentiment_by_year = sentiment_by_year[sentiment_order]\n",
    "\n",
    "\n",
    "# Create the stacked area chart\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sentiment_by_year.plot(kind='area', stacked=True,color=[colors[col] for col in sentiment_order], figsize=(15, 8))\n",
    "\n",
    "plt.title('Distribution of Sentiment Categories based on the year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Movies')\n",
    "\n",
    "# Set x-axis ticks to the years present in the grouped data\n",
    "ax.set_xticks(sentiment_by_year.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='Sentiment Category')\n",
    "plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Final results / comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment % from summary\n",
    "sentiment_pct = (\n",
    "    summary_with_sentiment_df['sentiment_category']\n",
    "    .value_counts(normalize=True) * 100\n",
    ").round(2)\n",
    "\n",
    "# Sentiment % from plot\n",
    "plot_sentiment_pct = (\n",
    "    summary_with_sentiment_df['plot_sentiment_category']\n",
    "    .value_counts(normalize=True) * 100\n",
    ").round(2)\n",
    "\n",
    "\n",
    "gpt_sentiment_pct = (\n",
    "    summary_gpt_df['emotional_category']\n",
    "    .value_counts(normalize=True) * 100\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_categories = [\n",
    "    \"Strongly Negative\",\n",
    "    \"Negative\",\n",
    "    \"Neutral\",\n",
    "    \"Positive\",\n",
    "    \"Strongly Positive\"\n",
    "]\n",
    "# Union of all categories\n",
    "all_categories = set(sentiment_pct.index) \\\n",
    "                 | set(plot_sentiment_pct.index) \\\n",
    "                 | set(gpt_sentiment_pct.index)\n",
    "\n",
    "# Calculate raw counts\n",
    "sentiment_counts = summary_with_sentiment_df['sentiment_category'].value_counts()\n",
    "plot_sentiment_counts = summary_with_sentiment_df['plot_sentiment_category'].value_counts()\n",
    "gpt_sentiment_counts = summary_gpt_df['emotional_category'].value_counts()\n",
    "\n",
    "# Reindex all with the full set\n",
    "sentiment_pct = sentiment_pct.reindex(ordered_categories, fill_value=0)\n",
    "plot_sentiment_pct = plot_sentiment_pct.reindex(ordered_categories, fill_value=0)\n",
    "gpt_sentiment_pct = gpt_sentiment_pct.reindex(ordered_categories, fill_value=0)\n",
    "\n",
    "# Reindex counts as well\n",
    "sentiment_counts = sentiment_counts.reindex(ordered_categories, fill_value=0)\n",
    "plot_sentiment_counts = plot_sentiment_counts.reindex(ordered_categories, fill_value=0)\n",
    "gpt_sentiment_counts = gpt_sentiment_counts.reindex(ordered_categories, fill_value=0)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "combined_pct = pd.DataFrame({\n",
    "    \"sentiment_category\": ordered_categories,\n",
    "    \"plot_percentage\": plot_sentiment_pct.values,\n",
    "    \"summary_percentage\": sentiment_pct.values,\n",
    "    \"gpt_percentage\": gpt_sentiment_pct.values\n",
    "})\n",
    "\n",
    "for col in [\"summary_percentage\", \"plot_percentage\", \"gpt_percentage\"]:\n",
    "    combined_pct[col] = (combined_pct[col]).astype(str) + '%'\n",
    "\n",
    "# Raw counts table\n",
    "combined_counts = pd.DataFrame({\n",
    "    \"sentiment_category\": ordered_categories,\n",
    "    \"plot_count\": plot_sentiment_counts.values,\n",
    "    \"summary_count\": sentiment_counts.values,\n",
    "    \"gpt_count\": gpt_sentiment_counts.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ¯ SENTIMENT ANALYSIS RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸ“ˆ PERCENTAGE DISTRIBUTION\")\n",
    "print(\"-\" * 40)\n",
    "print(combined_pct.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ“‹ RAW COUNT DISTRIBUTION\") \n",
    "print(\"-\" * 40)\n",
    "print(combined_counts.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ“Š SUMMARY STATISTICS\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"ðŸ“ Total Summary Records: {combined_counts['summary_count'].sum():,}\")\n",
    "print(f\"ðŸ“– Total Plot Records: {combined_counts['plot_count'].sum():,}\")\n",
    "print(f\"ðŸ¤– Total GPT Records: {combined_counts['gpt_count'].sum():,}\")\n",
    "\n",
    "# Most common sentiment for each method\n",
    "print(f\"\\nðŸ† Most Common Sentiments:\")\n",
    "print(f\"   Summary: {combined_counts.loc[combined_counts['summary_count'].idxmax(), 'sentiment_category']}\")\n",
    "print(f\"   Plot: {combined_counts.loc[combined_counts['plot_count'].idxmax(), 'sentiment_category']}\")  \n",
    "print(f\"   GPT: {combined_counts.loc[combined_counts['gpt_count'].idxmax(), 'sentiment_category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP2Hadg5LUlJ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NOT IN USE (additional tryout codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PULL THE INFORMATION FROM THE CARDS 1 BY 1\n",
    "\n",
    "#THIS PART IS RUNNING FOR 81 seconds for 50 titles\n",
    "#THIS PART IS RUNNING FOR 181 seconds for 100 titles\n",
    "#THIS PART WOULD RUN FOR approximately 81 MINUTES FOR THE WHOLE LIST - 2723 TITLES (11 PAGES)\n",
    "\n",
    "all_movies = []\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "for url in only_url[:100]:\n",
    "    current_movie = []\n",
    "    current_movie_data = []\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.content\n",
    "    soup = bs(html, \"lxml\")\n",
    "\n",
    "    ########\n",
    "    ## TITLE\n",
    "    ########\n",
    "    try:\n",
    "        title_element = soup.find('h1', attrs={'data-testid': 'hero__pageTitle'})\n",
    "        if title_element:\n",
    "            title = title_element.get_text(strip=True)\n",
    "            current_movie.append(title)\n",
    "    except:\n",
    "        print('no title found')\n",
    "\n",
    "    ########\n",
    "    ## YEAR\n",
    "    ########\n",
    "    try:\n",
    "      year_div = soup.find('ul', class_=\"ipc-inline-list ipc-inline-list--show-dividers sc-cb6a22b2-2 aFhKV baseAlt baseAlt\")\n",
    "      year_next_level = year_div.find('li', class_=\"ipc-inline-list__item\")\n",
    "      year = year_next_level.find('a').get_text(strip=True)\n",
    "      current_movie.append(year)\n",
    "    except:\n",
    "      print('no year found')\n",
    "\n",
    "    ##########\n",
    "    ## RATING\n",
    "    #########\n",
    "    try:\n",
    "        rating_span = soup.find('span', class_=\"sc-4dc495c1-1 lbQcRY\")\n",
    "        rating = rating_span.get_text(strip=True) if rating_span else None\n",
    "        current_movie.append(rating)\n",
    "    except Exception as e:\n",
    "        print(f'no rating found: {e}')\n",
    "\n",
    "    #############\n",
    "    ## SHORT PLOT\n",
    "    #############\n",
    "    try:\n",
    "      plot = soup.find_all(\"span\", class_=\"sc-bf30a0e-2 bRimta\")\n",
    "      current_movie.append(plot)\n",
    "    except:\n",
    "        print('no short plot found')\n",
    "\n",
    "    #############\n",
    "    ## AI SUMMARY\n",
    "    #############\n",
    "    try:\n",
    "      ai_summary = soup.find_all('div', class_='ipc-html-content-inner-div')\n",
    "      current_movie.append(ai_summary)\n",
    "    except:\n",
    "        print('no AI summary found')\n",
    "\n",
    "    ############################\n",
    "    ## PREPARING THE NESTED LIST\n",
    "    ############################\n",
    "    #TITLE\n",
    "    try:\n",
    "        current_movie_data.append(current_movie[0])\n",
    "    except:\n",
    "        current_movie_data.append(0)\n",
    "    \n",
    "    #YEAR\n",
    "    try:\n",
    "        current_movie_data.append(current_movie[1])\n",
    "    except:\n",
    "        current_movie_data.append(0)\n",
    "    \n",
    "    #RATING\n",
    "    try:\n",
    "        current_movie_data.append(current_movie[2])\n",
    "    except:\n",
    "        current_movie_data.append(0)\n",
    "    \n",
    "    #plot\n",
    "    try:\n",
    "        current_movie_data.append(current_movie[3])\n",
    "    except:\n",
    "        current_movie_data.append(0)\n",
    "    \n",
    "    #summary\n",
    "    try:\n",
    "        current_movie_data.append(current_movie[4])\n",
    "    except:\n",
    "        current_movie_data.append(0)\n",
    "\n",
    "    all_movies.append(current_movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each sentiment category\n",
    "plot_sentiment_category_counts = summary_with_sentiment_df['plot_sentiment_category'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot_sentiment_category_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Plot Sentiment Categories (5 Categories)')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
    "plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT\n",
    "#RUNNING FOR 150 seconds FOR 2700 TITLES\n",
    "sentiment_plot = []\n",
    "# Define the maximum sequence length for the model\n",
    "max_len = sentiment_analyzer.model.config.max_position_embeddings\n",
    "\n",
    "for plot in summary_df['plot']:\n",
    "    # Truncate the plot to the maximum length\n",
    "    truncated_plot = plot[:max_len]\n",
    "    result = sentiment_analyzer(truncated_plot)\n",
    "    sentiment_plot.append(result[0])\n",
    "\n",
    "summary_df['plot_sent'] = sentiment_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_labels = summary_df['sentiment'].apply(lambda x: x['label'])\n",
    "sentiment_counts = sentiment_labels.value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentiment_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUMMARY\n",
    "#RUNNING FOR 347 SECONDS FOR 2700 TITLES\n",
    "\n",
    "sentiments = []\n",
    "# Define the maximum sequence length for the model\n",
    "max_len = sentiment_analyzer.model.config.max_position_embeddings\n",
    "\n",
    "for summary in summary_df['summary']:\n",
    "    # Truncate the summary to the maximum length\n",
    "    truncated_summary = summary[:max_len]\n",
    "    result = sentiment_analyzer(truncated_summary)\n",
    "    sentiments.append(result[0])\n",
    "\n",
    "summary_df['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiment_labels = summary_df['sentiment'].apply(lambda x: x['label'])\n",
    "plot_sentiment_counts = plot_sentiment_labels.value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_sentiment_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Summary Sentiment Labels')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
